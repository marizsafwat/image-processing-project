{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_gB0gF4LSLP"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "v4YO9ZTvLSLS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import os\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import glob \n",
    "from moviepy.editor import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETfbSiiQ2yb7"
   },
   "source": [
    "# Camera Clibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "v8pqz3X02yb_"
   },
   "outputs": [],
   "source": [
    "mtx = [] \n",
    "dist =[]\n",
    "def calibration () :\n",
    "    object_points = [] # real world corners \n",
    "    img_points =[] # corners get using open cv \n",
    "    images = glob.glob('./camera_cal/*.jpg')\n",
    "    \n",
    "    objp = np.zeros((9*6, 3), np.float32)  # 3d object real life points \n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2) # to make it 2d [-1 in reshape to make it flexible ]\n",
    "\n",
    "    for f in images:\n",
    "        image = cv2.imread(f);\n",
    "        # Convert to grayscale image\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        # Find chessboard corners\n",
    "        ret,corners = cv2.findChessboardCorners(gray , (9,6) , None )\n",
    "\n",
    "        if ret:\n",
    "            img_points.append(corners) #the corners \n",
    "            object_points.append(objp) # the expected right corners \n",
    "\n",
    "        shape = (image.shape[1], image.shape[0]) # size of image \n",
    "        global mtx \n",
    "        global dist \n",
    "        ret, mtx, dist, _, _ = cv2.calibrateCamera(object_points, img_points, shape, None, None)\n",
    "        \n",
    "    return mtx,dist \n",
    "\n",
    "def undistort(img): \n",
    "    return cv2.undistort(img, mtx, dist, None, mtx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhtTdTTXLSLU"
   },
   "source": [
    "# Perspective Transfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "JLTHa4y5LSLU"
   },
   "outputs": [],
   "source": [
    "def Perspective_Transform(img):\n",
    "    #detected_image = canny(img) ; #output of canny detection \n",
    "    # Vertices extracted manually for performing a perspective transform\n",
    "    bottom_left = [150,720]\n",
    "    bottom_right = [1200, 720]\n",
    "    top_left = [550, 460]\n",
    "    top_right = [770, 460]\n",
    "\n",
    "    source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "    \n",
    "    # Destination points are chosen such that straight lanes appear more or less parallel in the transformed image.\n",
    "    bottom_left = [100,720]\n",
    "    bottom_right = [1100, 720]\n",
    "    top_left = [100, 0]\n",
    "    top_right = [1100, 0]\n",
    "\n",
    "    dst = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(source, dst) \n",
    "    # M is the matrix of perspective which mutliply with original and get the wrapped image\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, source)\n",
    "    #print(img.shape)\n",
    "    #img_size = (img.shape[1], img.shape[0]) \n",
    "    #warped = cv2.warpPerspective(detected_image, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    return M , M_inv\n",
    "\n",
    "# function to get top view from front view \n",
    "def forward_perspective(img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "    M , _  = Perspective_Transform(img)\n",
    "    return cv2.warpPerspective(img,M, img_size, flags=flags) \n",
    "\n",
    "# function to get front view from top view \n",
    "def backward_perspective( img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "    _ , M_inv  = Perspective_Transform(img)\n",
    "    return cv2.warpPerspective(img, M_inv, img_size, flags=flags)\n",
    "\n",
    "def detected_original(img) :\n",
    "    bottom_left = [150,720]\n",
    "    bottom_right = [1200, 720]\n",
    "    top_left = [550, 460]\n",
    "    top_right = [770, 460]\n",
    "    # Draw lines in image by these points by red color and its closed shape \n",
    "    pts = np.array([bottom_left,bottom_right,top_right,top_left], np.int32)\n",
    "    #print(pts,pts.shape)\n",
    "    pts = pts.reshape((-1,1,2)) # to make each point as a list\n",
    "    #print(pts,pts.shape)\n",
    "    copy = img.copy()\n",
    "    is_closed = True        \n",
    "    cv2.polylines(copy,[pts],is_closed,(255,0,0), thickness=3)  \n",
    "    return copy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDHoINdxXnCh"
   },
   "source": [
    "# FitLines function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "lHXTMhmULSLY"
   },
   "outputs": [],
   "source": [
    "left_fit = []\n",
    "right_fit = []\n",
    "\n",
    "def pixels_in_window(nonzerox,nonzeroy, center, margin, height):\n",
    "    topleft= (center[0]-margin, center[1]-height//2)\n",
    "    bottomright= (center[0]+margin, center[1]+height//2)\n",
    "    condx= (topleft[0] <= nonzerox) & (nonzerox<= bottomright[0])\n",
    "    condy= (topleft[1] <= nonzeroy) & (nonzeroy<= bottomright[1])\n",
    "    return nonzerox[condx&condy], nonzeroy[condx&condy]\n",
    "\n",
    "def fitlines(warped):\n",
    "#     left_fit = None\n",
    "#     right_fit = None\n",
    "    assert(len(warped.shape) ==2)\n",
    "    histogram=np.sum(warped[warped.shape[0]//2:,:],axis=0)\n",
    "    #plt.imshow(histogram)\n",
    "    midpoint=np.int(histogram.shape[0]/2)\n",
    "    leftx_base=np.argmax(histogram[:midpoint])\n",
    "    rightx_base=np.argmax(histogram[midpoint:])+midpoint\n",
    "    leftx=[]\n",
    "    lefty=[]\n",
    "    rightx=[]\n",
    "    righty=[]\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    windowsnum=9\n",
    "    window_height=int(warped.shape[0]/windowsnum)\n",
    "    leftx_curr=leftx_base\n",
    "    rightx_curr=rightx_base\n",
    "    halfWindowWidth=100\n",
    "    minpix = 50\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    y_current=warped.shape[0] + window_height//2\n",
    "# print(nonzero)\n",
    "# print(nonzerox)\n",
    "#print(nonzeroy)\n",
    "# print(warped)\n",
    "\n",
    "\n",
    "    for window in range(windowsnum):\n",
    "        \n",
    "        y_current -= window_height\n",
    "        center_left = (leftx_curr, y_current)\n",
    "        center_right= (rightx_curr, y_current)\n",
    "        \n",
    "        winYlow=warped.shape[0]-(window+1)*window_height\n",
    "        winYhigh=warped.shape[0]-window*window_height\n",
    "        win_xleft_low=leftx_curr-halfWindowWidth\n",
    "        win_xleft_high=leftx_curr+halfWindowWidth\n",
    "        win_xright_low=rightx_curr-halfWindowWidth\n",
    "        win_xright_high=rightx_curr+halfWindowWidth\n",
    "        cv2.rectangle(out_img,(win_xleft_low,winYlow),(win_xleft_high,winYhigh),\n",
    "          (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,winYlow),(win_xright_high,winYhigh),(0,255,0), 2) \n",
    "#         good_left_inds = ((nonzeroy >= winYlow) & (nonzeroy < winYhigh) & \n",
    "#           (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "#         good_right_inds = ((nonzeroy >= winYlow) & (nonzeroy < winYhigh) & \n",
    "#           (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "#         left_lane_inds.append(good_left_inds)\n",
    "#         right_lane_inds.append(good_right_inds)\n",
    "        good_left_x, good_left_y =pixels_in_window(nonzerox,nonzeroy,center_left, halfWindowWidth, window_height)\n",
    "        good_right_x, good_right_y =pixels_in_window(nonzerox,nonzeroy,center_right,halfWindowWidth, window_height)\n",
    "        \n",
    "        leftx.extend(good_left_x)\n",
    "        lefty.extend(good_left_y)  \n",
    "        rightx.extend(good_right_x)\n",
    "        righty.extend(good_right_y)\n",
    "        \n",
    "        if len(good_left_x) > minpix:\n",
    "              leftx_curr = int(np.mean(good_left_x))\n",
    "        if len(good_right_x) > minpix:        \n",
    "              rightx_curr = int(np.mean(good_right_x))\n",
    "\n",
    "    # print(good_left_inds)\n",
    "    # print(good_right_inds)\n",
    "    # print( nonzeroy,winYlow,nonzeroy >= winYlow)\n",
    "\n",
    "#     left_lane_inds = np.concatenate(left_lane_inds)\n",
    "#     right_lane_inds = np.concatenate(right_lane_inds)\n",
    "#     leftx = nonzerox[left_lane_inds]\n",
    " # lefty = nonzeroy[left_lane_inds] \n",
    "#     leftx.extend(nonzerox[left_lane_inds])\n",
    "#     lefty.extend(nonzeroy[left_lane_inds])\n",
    "#     rightx.extend(nonzerox[right_lane_inds])\n",
    "#     righty.extend(nonzeroy[right_lane_inds])\n",
    "#     rightx = nonzerox[right_lane_inds]\n",
    "#     righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "#     if len(leftx) == 0:\n",
    "#         left_fit =[]\n",
    "#     else:\n",
    "#         left_fit = np.polyfit(lefty, leftx, 2)\n",
    "  \n",
    "#     if len(rightx) == 0:\n",
    "#         right_fit =[]\n",
    "#     else:\n",
    "#         right_fit = np.polyfit(righty, rightx, 2)\n",
    "#    print(len(lefty))\n",
    "#    print(len(righty))\n",
    "    \n",
    "    if len(lefty) > 1500:\n",
    "        global left_fit\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "\n",
    "    if len(righty) > 1500:\n",
    "        global right_fit\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    #print(\"left_fit\",left_fit)\n",
    "    \n",
    "    out_img[lefty, leftx] = [255, 0, 0]   #newwwwww\n",
    "    out_img[righty, rightx] = [0, 0, 255] #newwwwww\n",
    "    \n",
    "    maxy = warped.shape[0] - 1\n",
    "    miny = warped.shape[0] // 3\n",
    "    if len(lefty):\n",
    "            maxy = max(maxy, np.max(lefty))\n",
    "            miny = min(miny, np.min(lefty))\n",
    "\n",
    "    if len(righty):\n",
    "            maxy = max(maxy, np.max(righty))\n",
    "            miny = min(miny, np.min(righty))\n",
    "\n",
    "    ploty = np.linspace(miny, maxy, warped.shape[0])\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "\n",
    "    return out_img, lefty, leftx, righty, rightx, ploty,histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lskmg5qyPD_h"
   },
   "source": [
    "## Radius_of_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "c9YcxbrzPIDj"
   },
   "outputs": [],
   "source": [
    "def lane_curvatures(lefty, leftx, righty, rightx, ploty):\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters to obtain the real curves values\n",
    "    # real object width / width in pixel\n",
    "    # we assume that the lane is 3.7 * 30 m;\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension 700 or 730\n",
    "    \n",
    "    y_eval = np.max(ploty) #the bottom point (height-1)(lowest point in picture)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    #make new polynomials with new values of x,y in meters\n",
    "\n",
    "    new_lefty = [i * ym_per_pix for i in lefty]\n",
    "    new_leftx = [i * xm_per_pix for i in leftx]\n",
    "    new_righty = [i * ym_per_pix for i in righty]\n",
    "    new_rightx = [i * xm_per_pix for i in rightx]\n",
    "\n",
    "    left_fit_cr = np.polyfit(new_lefty, new_leftx, 2) #returns coeff of second order function from highest to lowest\n",
    "    right_fit_cr = np.polyfit(new_righty, new_rightx, 2) #second order because it is a curve\n",
    "\n",
    "    # Calculate the new radii of curvature in meters to represent them\n",
    "    # R=(1+(x')**2)**1.5/abs(x'');\n",
    "    # equation=ax**2+bx+c, a=_fit_cr[0],b=_fit_cr[1],c=_fit_cr[2]\n",
    "    # x is the value of y_eval which satisfies the equation but in meters\n",
    "    # x'=2ay+b\n",
    "    # x''=2a\n",
    "\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    #take the average of the 2 curves\n",
    "    radius = round((float(left_curverad) + float(right_curverad))/2.,2)\n",
    "\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4nFtHy4PLi0"
   },
   "source": [
    "# Draw_Lane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "z90Icnm9PRmf"
   },
   "outputs": [],
   "source": [
    "def draw_lane(warped, ploty):\n",
    "\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8) #make a picture like \"wrap\" all zeroes with type 8 bit each 0:255\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero)) # make it an array of 3 elements\n",
    "    \n",
    "    #get the output of the second order equation obtained from plotted points :ax**2+bx+c\n",
    "    # a=left_fit[0],b=left_fit[1],c=left_fit[2]\n",
    "    #to get the x coordinates for the ploty array\n",
    "\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the dark image with the array of points calculated in a prespective view\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (255,0, 0)) #draw with green\n",
    "\n",
    "    \n",
    "    return color_warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating car postion relative to lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_car_position(binary_warped, left_fit, right_fit):\n",
    "    # Define conversion in x from pixels space to meters\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Choose the y value corresponding to the bottom of the image\n",
    "    y_max = binary_warped.shape[0]\n",
    "    # Calculate left and right line positions at the bottom of the image\n",
    "    left_x_pos = left_fit[0]*y_max**2 + left_fit[1]*y_max + left_fit[2]\n",
    "    right_x_pos = right_fit[0]*y_max**2 + right_fit[1]*y_max + right_fit[2] \n",
    "    # Calculate the x position of the center of the lane \n",
    "    center_lanes_x_pos = (left_x_pos + right_x_pos)//2\n",
    "    # Calculate the deviation between the center of the lane and the center of the picture\n",
    "    # The car is assumed to be placed in the center of the picture\n",
    "    # If the deviation is negative, the car is on the left hand side of the center of the lane\n",
    "    car_pos = ((binary_warped.shape[1]//2) - center_lanes_x_pos) * xm_per_pix \n",
    "    \n",
    "    return car_pos,center_lanes_x_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding text to video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_text(final_img, car_pos,radius):\n",
    "     # Using CV2 putText to write text into images\n",
    "    #(image,text,co-ordinates of bottom left,font type,scale,colour,thickness,linetype)\n",
    "    #cv2.putText(final_img, TextL, (110,60), fontFace, fontScale,(255,255,255), thickness,  lineType = cv2.LINE_AA)\n",
    "    cv2.putText(final_img,'Radius of Curvature: '+str(radius)[:7]+' m',(40,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    if car_pos > 0:\n",
    "        cv2.putText(final_img,'Vehicle is '+str(car_pos)[:7]+'m right of center',(40,150), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif car_pos < 0:\n",
    "        cv2.putText(final_img,'Vehicle is '+str(abs(car_pos))[:7]+'m left of center',(40,150), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(final_img,'Vehicle is '+str(car_pos)[:7]+'at the center',(40,150), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw_vertical_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vertical_lines(xposition,image):\n",
    "  line1=cv2.line(image,(int(image.shape[1]/2),720),(int(image.shape[1]/2),650),(255,255,255),10) #center of pic\n",
    "  line2=cv2.line(image,(int(xposition),720),(int(xposition),650),(0,0,255),10) #center of lane\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing images and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_number=0\n",
    "\n",
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "\n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "def process_image(img):\n",
    "    # step 1:returning image in plane view\n",
    "    #print(op_number)\n",
    "    \n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img_binary) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) #new binary image \n",
    "    \n",
    "    if (op_number=='2'):\n",
    "        return img_binary\n",
    "    \n",
    "    first_detection = detected_original(img) #newwwwwwwwwwww\n",
    "    if (op_number=='8'):\n",
    "        return first_detection\n",
    "    un_distort = undistort(img) #newwwwwwwwwwww\n",
    "   \n",
    "    img1=forward_perspective(un_distort) #newwwwwwwwwwww\n",
    "    \n",
    "    # step 2: thresholding\n",
    "    hls = cv2.cvtColor(img1, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img1, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    v_channel = hsv[:,:,2]\n",
    "    vmin= np.min(s_channel)\n",
    "    vmax= np.max(s_channel)\n",
    "    \n",
    "    right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "    right_lane[:,:750] = 0\n",
    "    \n",
    "    left_lane = threshold_abs(h_channel, 20, 30)\n",
    "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "    left_lane[:,550:] = 0\n",
    "    img2 = left_lane | right_lane #returns warped binary images of the two lanes\n",
    "    \n",
    "    if(op_number=='4'):\n",
    "        return img2\n",
    "    #cv2.imshow(\"image2\",img2)\n",
    "    # step 3: detect lane edged and draw lane \n",
    "    slidding, lefty, leftx, righty, rightx, ploty,histogram = fitlines(img2)\n",
    "    \n",
    "    if(op_number=='3'):\n",
    "        return slidding\n",
    "    \n",
    "    radius = lane_curvatures(lefty, leftx, righty, rightx, ploty) #radius of curvature calculation\n",
    "    #radius=10\n",
    "    car_pos,center_lanes_x_pos = measure_car_position(img2, left_fit, right_fit) #returns car pos\n",
    "    img3=draw_lane(img2, ploty)\n",
    "    \n",
    "    if(op_number=='5'):\n",
    "        return img3\n",
    "    \n",
    "    # step 4 : returning normal prespective black photo with drawn lane\n",
    "    img4 = backward_perspective(img3)\n",
    "    \n",
    "    if(op_number=='6'):\n",
    "        return img4\n",
    "    \n",
    "    out_img = cv2.addWeighted(img, 1, img4, 1, 0) \n",
    "    final_out_img = adding_text(out_img,car_pos,radius)\n",
    "    output_img = draw_vertical_lines(center_lanes_x_pos,final_out_img)\n",
    "    \n",
    "    if(op_number=='7'):\n",
    "        return final_out_img\n",
    "    \n",
    "    merged_photo_x1=np.hstack((output_img,img1))\n",
    "    #merged_photo_x2=np.hstack((img2,out_img))\n",
    "    merged_photo_x3=np.hstack((img3,img4))\n",
    "    merged_photo=np.vstack((merged_photo_x1,merged_photo_x3))\n",
    "    #merged_photo=np.vstack((merged_photo_v1,out_img))\n",
    "    \n",
    "    if(op_number=='8'):\n",
    "        return merged_photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_image(path):\n",
    "    image = mpimg.imread(path)\n",
    "    #print(image.shape)\n",
    "    calibration()\n",
    "    tmp = process_image(image)\n",
    "    mpimg.imsave('output image.jpg',tmp)\n",
    "    #plt.imshow(\"output picture\",tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3YLXFVILSLX"
   },
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(path):\n",
    "    calibration()\n",
    "    clip = VideoFileClip(path)\n",
    "    out_clip = clip.fl_image(process_image)\n",
    "    out_clip.write_videofile(\"output.mp4\",fps=clip.fps, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "OBDCbaiHJtrl"
   },
   "outputs": [],
   "source": [
    "def read_video(path):\n",
    "    clip = VideoFileClip(\"C:/Users/mariz/Downloads/image processing/test/Project_data/project_video.mp4\")\n",
    "    out_clip = clip.fl_image(process_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"WELCOME TO OUR LANE DETECTION PROGRAM\")\n",
    "    print(\"DO you want to input : 1-image 2-video\")\n",
    "    x=input(\"please enter 1 or 2\")   \n",
    "    path = input(\"Enter the path of your file: \") \n",
    "    assert os.path.exists(path), \"I did not find the file at, \"+str(user_input)\n",
    "    while (1):\n",
    "        print(\"what operation do you want to make on the video : \")\n",
    "        print(\"1: edge fence\") #first detection\n",
    "        print(\"2: Binary image\") #lesa\n",
    "        print(\"3: sliding window algorithm\") #sliding\n",
    "        print(\"4: Binary plan view\") #image2\n",
    "        print(\"5: highlighted lane plane view\") #image3\n",
    "        print(\"6: highlighted lane plane\") #image4\n",
    "        print(\"7: the final video\") #final output video\n",
    "        print(\"8: mix of different output videos\")\n",
    "        global op_number\n",
    "        op_number= input(\"choose the operation number: \")\n",
    "        if (x == '1'): #image\n",
    "            take_image(path)\n",
    "        else: \n",
    "            process_video(path)\n",
    "        print(\"you can now preview the saved output\")    \n",
    "        letter=input(\"Do you want to make another opertaion ? y/n\")\n",
    "        if (letter=='n'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELCOME TO OUR LANE DETECTION PROGRAM\n",
      "DO you want to input : 1-image 2-video\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28144/3832242952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28144/1790088422.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"WELCOME TO OUR LANE DETECTION PROGRAM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DO you want to input : 1-image 2-video\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"please enter 1 or 2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the path of your file: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"I did not find the file at, \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
