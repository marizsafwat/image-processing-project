{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_gB0gF4LSLP"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v4YO9ZTvLSLS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from numpy import array\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import os\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import glob \n",
    "from moviepy.editor import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETfbSiiQ2yb7"
   },
   "source": [
    "# Camera Clibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v8pqz3X02yb_"
   },
   "outputs": [],
   "source": [
    "mtx = [] \n",
    "dist =[]\n",
    "def calibration () :\n",
    "    object_points = [] # real world corners \n",
    "    img_points =[] # corners get using open cv \n",
    "    images = glob.glob('./camera_cal/*.jpg')\n",
    "    \n",
    "    objp = np.zeros((9*6, 3), np.float32)  # 3d object real life points \n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2) # to make it 2d [-1 in reshape to make it flexible ]\n",
    "\n",
    "    for f in images:\n",
    "        image = cv2.imread(f);\n",
    "        # Convert to grayscale image\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        # Find chessboard corners\n",
    "        ret,corners = cv2.findChessboardCorners(gray , (9,6) , None )\n",
    "\n",
    "        if ret:\n",
    "            img_points.append(corners) #the corners \n",
    "            object_points.append(objp) # the expected right corners \n",
    "\n",
    "        shape = (image.shape[1], image.shape[0]) # size of image \n",
    "        global mtx \n",
    "        global dist \n",
    "        ret, mtx, dist, _, _ = cv2.calibrateCamera(object_points, img_points, shape, None, None)\n",
    "        \n",
    "    return mtx,dist \n",
    "\n",
    "def undistort(img): \n",
    "    return cv2.undistort(img, mtx, dist, None, mtx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhtTdTTXLSLU"
   },
   "source": [
    "# Perspective Transfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JLTHa4y5LSLU"
   },
   "outputs": [],
   "source": [
    "def Perspective_Transform(img):\n",
    "    #detected_image = canny(img) ; #output of canny detection \n",
    "    # Vertices extracted manually for performing a perspective transform\n",
    "    bottom_left = [150,720]\n",
    "    bottom_right = [1200, 720]\n",
    "    top_left = [550, 460]\n",
    "    top_right = [770, 460]\n",
    "\n",
    "    source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "    \n",
    "    # Destination points are chosen such that straight lanes appear more or less parallel in the transformed image.\n",
    "    bottom_left = [100,720]\n",
    "    bottom_right = [1100, 720]\n",
    "    top_left = [100, 0]\n",
    "    top_right = [1100, 0]\n",
    "\n",
    "    dst = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(source, dst) \n",
    "    # M is the matrix of perspective which mutliply with original and get the wrapped image\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, source)\n",
    "    #print(img.shape)\n",
    "    #img_size = (img.shape[1], img.shape[0]) \n",
    "    #warped = cv2.warpPerspective(detected_image, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    return M , M_inv\n",
    "\n",
    "# function to get top view from front view \n",
    "def forward_perspective(img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "    M , _  = Perspective_Transform(img)\n",
    "    return cv2.warpPerspective(img,M, img_size, flags=flags) \n",
    "\n",
    "# function to get front view from top view \n",
    "def backward_perspective( img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "    _ , M_inv  = Perspective_Transform(img)\n",
    "    return cv2.warpPerspective(img, M_inv, img_size, flags=flags)\n",
    "\n",
    "def detected_original(img) :\n",
    "    bottom_left = [150,720]\n",
    "    bottom_right = [1200, 720]\n",
    "    top_left = [550, 460]\n",
    "    top_right = [770, 460]\n",
    "    # Draw lines in image by these points by red color and its closed shape \n",
    "    pts = np.array([bottom_left,bottom_right,top_right,top_left], np.int32)\n",
    "    #print(pts,pts.shape)\n",
    "    pts = pts.reshape((-1,1,2)) # to make each point as a list\n",
    "    #print(pts,pts.shape)\n",
    "    copy = img.copy()\n",
    "    is_closed = True        \n",
    "    cv2.polylines(copy,[pts],is_closed,(255,0,0), thickness=3)  \n",
    "    return copy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDHoINdxXnCh"
   },
   "source": [
    "# FitLines function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lHXTMhmULSLY"
   },
   "outputs": [],
   "source": [
    "left_fit = []\n",
    "right_fit = []\n",
    "\n",
    "def pixels_in_window(nonzerox,nonzeroy, center, margin, height):\n",
    "    topleft= (center[0]-margin, center[1]-height//2)\n",
    "    bottomright= (center[0]+margin, center[1]+height//2)\n",
    "    condx= (topleft[0] <= nonzerox) & (nonzerox<= bottomright[0])\n",
    "    condy= (topleft[1] <= nonzeroy) & (nonzeroy<= bottomright[1])\n",
    "    return nonzerox[condx&condy], nonzeroy[condx&condy]\n",
    "\n",
    "def fitlines(warped):\n",
    "#     left_fit = None\n",
    "#     right_fit = None\n",
    "    assert(len(warped.shape) ==2)\n",
    "    histogram=np.sum(warped[warped.shape[0]//2:,:],axis=0)\n",
    "    #plt.imshow(histogram)\n",
    "    midpoint=np.int(histogram.shape[0]/2)\n",
    "    leftx_base=np.argmax(histogram[:midpoint])\n",
    "    rightx_base=np.argmax(histogram[midpoint:])+midpoint\n",
    "    leftx=[]\n",
    "    lefty=[]\n",
    "    rightx=[]\n",
    "    righty=[]\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    windowsnum=9\n",
    "    window_height=int(warped.shape[0]/windowsnum)\n",
    "    leftx_curr=leftx_base\n",
    "    rightx_curr=rightx_base\n",
    "    halfWindowWidth=100\n",
    "    minpix = 50\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    y_current=warped.shape[0] + window_height//2\n",
    "# print(nonzero)\n",
    "# print(nonzerox)\n",
    "#print(nonzeroy)\n",
    "# print(warped)\n",
    "\n",
    "\n",
    "    for window in range(windowsnum):\n",
    "        \n",
    "        y_current -= window_height\n",
    "        center_left = (leftx_curr, y_current)\n",
    "        center_right= (rightx_curr, y_current)\n",
    "        \n",
    "        winYlow=warped.shape[0]-(window+1)*window_height\n",
    "        winYhigh=warped.shape[0]-window*window_height\n",
    "        win_xleft_low=leftx_curr-halfWindowWidth\n",
    "        win_xleft_high=leftx_curr+halfWindowWidth\n",
    "        win_xright_low=rightx_curr-halfWindowWidth\n",
    "        win_xright_high=rightx_curr+halfWindowWidth\n",
    "        cv2.rectangle(out_img,(win_xleft_low,winYlow),(win_xleft_high,winYhigh),\n",
    "          (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,winYlow),(win_xright_high,winYhigh),(0,255,0), 2) \n",
    "#         good_left_inds = ((nonzeroy >= winYlow) & (nonzeroy < winYhigh) & \n",
    "#           (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "#         good_right_inds = ((nonzeroy >= winYlow) & (nonzeroy < winYhigh) & \n",
    "#           (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "#         left_lane_inds.append(good_left_inds)\n",
    "#         right_lane_inds.append(good_right_inds)\n",
    "        good_left_x, good_left_y =pixels_in_window(nonzerox,nonzeroy,center_left, halfWindowWidth, window_height)\n",
    "        good_right_x, good_right_y =pixels_in_window(nonzerox,nonzeroy,center_right,halfWindowWidth, window_height)\n",
    "        \n",
    "        leftx.extend(good_left_x)\n",
    "        lefty.extend(good_left_y)  \n",
    "        rightx.extend(good_right_x)\n",
    "        righty.extend(good_right_y)\n",
    "        \n",
    "        if len(good_left_x) > minpix:\n",
    "              leftx_curr = int(np.mean(good_left_x))\n",
    "        if len(good_right_x) > minpix:        \n",
    "              rightx_curr = int(np.mean(good_right_x))\n",
    "\n",
    "    # print(good_left_inds)\n",
    "    # print(good_right_inds)\n",
    "    # print( nonzeroy,winYlow,nonzeroy >= winYlow)\n",
    "\n",
    "#     left_lane_inds = np.concatenate(left_lane_inds)\n",
    "#     right_lane_inds = np.concatenate(right_lane_inds)\n",
    "#     leftx = nonzerox[left_lane_inds]\n",
    " # lefty = nonzeroy[left_lane_inds] \n",
    "#     leftx.extend(nonzerox[left_lane_inds])\n",
    "#     lefty.extend(nonzeroy[left_lane_inds])\n",
    "#     rightx.extend(nonzerox[right_lane_inds])\n",
    "#     righty.extend(nonzeroy[right_lane_inds])\n",
    "#     rightx = nonzerox[right_lane_inds]\n",
    "#     righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "#     if len(leftx) == 0:\n",
    "#         left_fit =[]\n",
    "#     else:\n",
    "#         left_fit = np.polyfit(lefty, leftx, 2)\n",
    "  \n",
    "#     if len(rightx) == 0:\n",
    "#         right_fit =[]\n",
    "#     else:\n",
    "#         right_fit = np.polyfit(righty, rightx, 2)\n",
    "#    print(len(lefty))\n",
    "#    print(len(righty))\n",
    "    \n",
    "    if len(lefty) > 1500:\n",
    "        global left_fit\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "\n",
    "    if len(righty) > 1500:\n",
    "        global right_fit\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    #print(\"left_fit\",left_fit)\n",
    "    \n",
    "    out_img[lefty, leftx] = [255, 0, 0]   #newwwwww\n",
    "    out_img[righty, rightx] = [0, 0, 255] #newwwwww\n",
    "    \n",
    "    maxy = warped.shape[0] - 1\n",
    "    miny = warped.shape[0] // 3\n",
    "    if len(lefty):\n",
    "            maxy = max(maxy, np.max(lefty))\n",
    "            miny = min(miny, np.min(lefty))\n",
    "\n",
    "    if len(righty):\n",
    "            maxy = max(maxy, np.max(righty))\n",
    "            miny = min(miny, np.min(righty))\n",
    "\n",
    "    ploty = np.linspace(miny, maxy, warped.shape[0])\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "\n",
    "    return out_img, lefty, leftx, righty, rightx, ploty,histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lskmg5qyPD_h"
   },
   "source": [
    "## Radius_of_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c9YcxbrzPIDj"
   },
   "outputs": [],
   "source": [
    "def lane_curvatures(lefty, leftx, righty, rightx, ploty):\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters to obtain the real curves values\n",
    "    # real object width / width in pixel\n",
    "    # we assume that the lane is 3.7 * 30 m;\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension 700 or 730\n",
    "    \n",
    "    y_eval = np.max(ploty) #the bottom point (height-1)(lowest point in picture)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    #make new polynomials with new values of x,y in meters\n",
    "\n",
    "    new_lefty = [i * ym_per_pix for i in lefty]\n",
    "    new_leftx = [i * xm_per_pix for i in leftx]\n",
    "    new_righty = [i * ym_per_pix for i in righty]\n",
    "    new_rightx = [i * xm_per_pix for i in rightx]\n",
    "\n",
    "    left_fit_cr = np.polyfit(new_lefty, new_leftx, 2) #returns coeff of second order function from highest to lowest\n",
    "    right_fit_cr = np.polyfit(new_righty, new_rightx, 2) #second order because it is a curve\n",
    "\n",
    "    # Calculate the new radii of curvature in meters to represent them\n",
    "    # R=(1+(x')**2)**1.5/abs(x'');\n",
    "    # equation=ax**2+bx+c, a=_fit_cr[0],b=_fit_cr[1],c=_fit_cr[2]\n",
    "    # x is the value of y_eval which satisfies the equation but in meters\n",
    "    # x'=2ay+b\n",
    "    # x''=2a\n",
    "\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    #take the average of the 2 curves\n",
    "    radius = round((float(left_curverad) + float(right_curverad))/2.,2)\n",
    "\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4nFtHy4PLi0"
   },
   "source": [
    "# Draw_Lane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z90Icnm9PRmf"
   },
   "outputs": [],
   "source": [
    "def draw_lane(warped, ploty):\n",
    "\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8) #make a picture like \"wrap\" all zeroes with type 8 bit each 0:255\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero)) # make it an array of 3 elements\n",
    "    \n",
    "    #get the output of the second order equation obtained from plotted points :ax**2+bx+c\n",
    "    # a=left_fit[0],b=left_fit[1],c=left_fit[2]\n",
    "    #to get the x coordinates for the ploty array\n",
    "\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the dark image with the array of points calculated in a prespective view\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (100,0, 100)) \n",
    "\n",
    "    \n",
    "    return color_warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating car postion relative to lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_car_position(binary_warped, left_fit, right_fit):\n",
    "    # Define conversion in x from pixels space to meters\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Choose the y value corresponding to the bottom of the image\n",
    "    y_max = binary_warped.shape[0]\n",
    "    # Calculate left and right line positions at the bottom of the image\n",
    "    left_x_pos = left_fit[0]*y_max**2 + left_fit[1]*y_max + left_fit[2]\n",
    "    right_x_pos = right_fit[0]*y_max**2 + right_fit[1]*y_max + right_fit[2] \n",
    "    # Calculate the x position of the center of the lane \n",
    "    center_lanes_x_pos = (left_x_pos + right_x_pos)//2\n",
    "    # Calculate the deviation between the center of the lane and the center of the picture\n",
    "    # The car is assumed to be placed in the center of the picture\n",
    "    # If the deviation is negative, the car is on the left hand side of the center of the lane\n",
    "    car_pos = ((binary_warped.shape[1]//2) - center_lanes_x_pos) * xm_per_pix \n",
    "    \n",
    "    return car_pos,center_lanes_x_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding text to video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_text(final_img, car_pos,radius):\n",
    "     # Using CV2 putText to write text into images\n",
    "    #(image,text,co-ordinates of bottom left,font type,scale,colour,thickness,linetype)\n",
    "    #cv2.putText(final_img, TextL, (110,60), fontFace, fontScale,(255,255,255), thickness,  lineType = cv2.LINE_AA)\n",
    "    cv2.putText(final_img,'Radius of Curvature: '+str(radius)[:7]+' m',(40,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(final_img,'Car center postion to lane: '+str(car_pos)[:7]+' m',(40,130), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.6,(255,255,255),2,cv2.LINE_AA)\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw_vertical_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vertical_lines(xposition,image):\n",
    "  line1=cv2.line(image,(int(image.shape[1]/2),720),(int(image.shape[1]/2),650),(255,255,255),10) #center of pic\n",
    "  line2=cv2.line(image,(int(xposition),720),(int(xposition),650),(0,0,255),10) #center of lane\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting merged picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for vertically \n",
    "# concatenating images of different\n",
    "# widths \n",
    "def vconcat_resize(img_list, interpolation \n",
    "                   = cv2.INTER_CUBIC):\n",
    "      # take minimum width\n",
    "    w_min = min(img.shape[1] \n",
    "                for img in img_list)\n",
    "      \n",
    "    # resizing images\n",
    "    im_list_resize = [cv2.resize(img,\n",
    "                      (w_min, int(img.shape[0] * w_min / img.shape[1])),\n",
    "                                 interpolation = interpolation)\n",
    "                      for img in img_list]\n",
    "    # return final image\n",
    "    return cv2.vconcat(im_list_resize)\n",
    "  \n",
    "# define a function for horizontally \n",
    "# concatenating images of different\n",
    "# heights \n",
    "def hconcat_resize(img_list, \n",
    "                   interpolation \n",
    "                   = cv2.INTER_CUBIC):\n",
    "      # take minimum hights\n",
    "    h_min = min(img.shape[0] \n",
    "                for img in img_list)\n",
    "      \n",
    "    # image resizing \n",
    "    im_list_resize = [cv2.resize(img,\n",
    "                       (int(img.shape[1] * h_min / img.shape[0]),\n",
    "                        h_min), interpolation\n",
    "                                 = interpolation) \n",
    "                      for img in img_list]\n",
    "      \n",
    "    # return final image\n",
    "    return cv2.hconcat(im_list_resize)\n",
    "  \n",
    "# define a function for concatenating\n",
    "# images of different sizes in\n",
    "# vertical and horizontal tiles\n",
    "def concat_tile_resize(list_2d, \n",
    "                       interpolation = cv2.INTER_CUBIC):\n",
    "      # function calling for every \n",
    "    # list of images\n",
    "    img_list_v = [hconcat_resize(list_h, \n",
    "                                 interpolation = cv2.INTER_CUBIC) \n",
    "                  for list_h in list_2d]\n",
    "      \n",
    "    # return final image\n",
    "    return vconcat_resize(img_list_v, interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing images and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_number=0\n",
    "\n",
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "\n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "def process_image(img):\n",
    "    # step 1:returning image in plane view\n",
    "    #print(op_number)\n",
    "    \n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img_binary) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) #new binary image \n",
    "    \n",
    "    if (op_number=='2'):\n",
    "        return img_binary\n",
    "    \n",
    "    first_detection = detected_original(img) #newwwwwwwwwwww\n",
    "    if (op_number=='1'):\n",
    "        return first_detection\n",
    "    un_distort = undistort(img) #newwwwwwwwwwww\n",
    "   \n",
    "    img1=forward_perspective(un_distort) #newwwwwwwwwwww\n",
    "    \n",
    "    # step 2: thresholding\n",
    "    hls = cv2.cvtColor(img1, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img1, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    v_channel = hsv[:,:,2]\n",
    "    vmin= np.min(s_channel)\n",
    "    vmax= np.max(s_channel)\n",
    "    \n",
    "    right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "    right_lane[:,:750] = 0\n",
    "    \n",
    "    left_lane = threshold_abs(h_channel, 20, 30)\n",
    "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "    left_lane[:,550:] = 0\n",
    "    img2 = left_lane | right_lane #returns warped binary images of the two lanes\n",
    "    \n",
    "    if(op_number=='4'):\n",
    "        return img2\n",
    "    #cv2.imshow(\"image2\",img2)\n",
    "    # step 3: detect lane edged and draw lane \n",
    "    slidding, lefty, leftx, righty, rightx, ploty,histogram = fitlines(img2)\n",
    "    \n",
    "    if(op_number=='3'):\n",
    "        return slidding\n",
    "    \n",
    "    radius = lane_curvatures(lefty, leftx, righty, rightx, ploty) #radius of curvature calculation\n",
    "    #radius=10\n",
    "    car_pos,center_lanes_x_pos = measure_car_position(img2, left_fit, right_fit) #returns car pos\n",
    "    img3=draw_lane(img2, ploty)\n",
    "    \n",
    "    if(op_number=='5'):\n",
    "        return img3\n",
    "    \n",
    "    # step 4 : returning normal prespective black photo with drawn lane\n",
    "    img4 = backward_perspective(img3)\n",
    "    \n",
    "    if(op_number=='6'):\n",
    "        return img4\n",
    "    \n",
    "    out_img = cv2.addWeighted(img, 1, img4, 1, 0) \n",
    "    final_out_img = adding_text(out_img,car_pos,radius)\n",
    "    output_img = draw_vertical_lines(center_lanes_x_pos,final_out_img)\n",
    "    \n",
    "    if(op_number=='7'):\n",
    "        return final_out_img\n",
    "    \n",
    "    height, width = 1080, 1920\n",
    "    FinalScreen = np.array((height,width),float)\n",
    "    #FinalScreen=array[1081][1921]\n",
    "    FinalScreen[0:720,0:1280] = cv2.resize(output_img, (1280,720), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[0:360,1280:1920] = cv2.resize(first_detection, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    #cv2.imshow(\"screen\",FinalScreen)\n",
    "    FinalScreen[360:720,1280:1920] = cv2.resize(img_binary, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,1280:1920] = cv2.resize(slidding, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,0:640] = cv2.resize(img3, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,640:1280] = cv2.resize(img4, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    #Merging pictures\n",
    "    out_binary_img = cv2.cvtColor(img_binary,cv2.COLOR_GRAY2BGR)\n",
    "    out_img2= cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    pic1= hconcat_resize([out_img2,img3]) #returns merged horizontal pictures\n",
    "    pic2= vconcat_resize([img,out_binary_img,slidding]) ##return merged vertival pictures ###change \"img\" to tharwat's pic####\n",
    "    pic3=concat_tile_resize([[final_out_img],[out_img2,img3]]) #return final_out_img with other pictures underneath\n",
    "    merged = hconcat_resize([pic3,pic2])\n",
    "    \n",
    "    if(op_number=='8'):\n",
    "        return FinalScreen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_image(path):\n",
    "    image = mpimg.imread(path)\n",
    "    #print(image.shape)\n",
    "    tmp = process_image(image)\n",
    "    #mpimg.imsave('output image.jpg',tmp)\n",
    "    plt.imshow(\"output picture\",tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3YLXFVILSLX"
   },
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(path):\n",
    "    clip = VideoFileClip(path)\n",
    "    out_clip = clip.fl_image(process_image)\n",
    "    out_clip.write_videofile(\"output.mp4\",fps=clip.fps, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print(\"WELCOME TO OUR LANE DETECTION PROGRAM\")\n",
    "    print(\"DO you want to input : 1-image 2-video\")\n",
    "    x=input(\"please enter 1 or 2\")   \n",
    "    path = input(\"Enter the path of your file: \") \n",
    "    calibration()\n",
    "    assert os.path.exists(path), \"I did not find the file at, \"+str(path)\n",
    "    while (1):\n",
    "        print(\"what operation do you want to make on the input : \")\n",
    "        print(\"1: edge fence\") #first detection\n",
    "        print(\"2: Binary image\") #lesa\n",
    "        print(\"3: sliding window algorithm\") #sliding\n",
    "        print(\"4: Binary plan view\") #image2\n",
    "        print(\"5: highlighted lane plane view\") #image3\n",
    "        print(\"6: highlighted lane plane\") #image4\n",
    "        print(\"7: the final output\") #final output video\n",
    "        print(\"8: debugging mode\")\n",
    "        global op_number\n",
    "        op_number= input(\"choose the operation number: \")\n",
    "        \n",
    "        if (x == '1'): #image\n",
    "            take_image(path)\n",
    "        else: \n",
    "            process_video(path)\n",
    "        print(\"you can now preview the saved output\")    \n",
    "        letter=input(\"Do you want to make another opertaion ? y/n\")\n",
    "        if (letter=='n'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELCOME TO OUR LANE DETECTION PROGRAM\n",
      "DO you want to input : 1-image 2-video\n",
      "please enter 1 or 21\n",
      "Enter the path of your file: C:/Users/mariz/Documents/GitHub/image-processing-project/test_images/test2.jpg\n",
      "what operation do you want to make on the input : \n",
      "1: edge fence\n",
      "2: Binary image\n",
      "3: sliding window algorithm\n",
      "4: Binary plan view\n",
      "5: highlighted lane plane view\n",
      "6: highlighted lane plane\n",
      "7: the final output\n",
      "8: debugging mode\n",
      "choose the operation number: 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8344/3832242952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8344/3117363149.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mtake_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mprocess_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8344/2337013647.py\u001b[0m in \u001b[0;36mtake_image\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#print(image.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#mpimg.imsave('output image.jpg',tmp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"output picture\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8344/4124273946.py\u001b[0m in \u001b[0;36mprocess_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mFinalScreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m#FinalScreen=array[1081][1921]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mFinalScreen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1280\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1280\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mFinalScreen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1280\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1920\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_detection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m#cv2.imshow(\"screen\",FinalScreen)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
